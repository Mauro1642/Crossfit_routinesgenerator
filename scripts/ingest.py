"""
ingest.py
---------
Este m√≥dulo carga las rutinas procesadas (JSON) en ChromaDB, la base de datos
vectorial que usa el sistema RAG para recuperar rutinas similares.

Cada semana se almacena como un documento vectorizado. ChromaDB convierte
el texto de cada rutina en un vector num√©rico (embedding) que representa
su "significado" en un espacio matem√°tico. Cuando el usuario pide una rutina
nueva, el sistema busca los vectores m√°s cercanos al pedido y los usa como
contexto para la generaci√≥n.

Flujo:
    JSON procesado --> texto enriquecido --> ChromaDB (embedding + metadata) --> listo para RAG
"""

import json
from pathlib import Path

import chromadb
from chromadb.utils import embedding_functions
from dotenv import load_dotenv

# ---------------------------------------------------------------------------
# Carga las variables de entorno desde .env (necesario para la API key de OpenAI
# que usa ChromaDB internamente para generar los embeddings)
# ---------------------------------------------------------------------------
load_dotenv()

# ===========================================================================
# CONFIGURACI√ìN
# Constantes que definen c√≥mo se conecta y organiza la base de datos vectorial
# ===========================================================================

# Carpeta donde ChromaDB persiste los datos en disco entre ejecuciones
# Si no existe, ChromaDB la crea autom√°ticamente
CHROMA_DB_PATH = "./chroma_db"

# Nombre de la colecci√≥n dentro de ChromaDB donde se guardan las rutinas
# Una colecci√≥n es similar a una tabla en SQL
COLLECTION_NAME = "rutinas_crossfit"

# Carpeta donde est√°n los JSONs procesados por parse_routine.py
PROCESSED_DATA_PATH = "./data/processed"


# ===========================================================================
# FUNCIONES DE TRANSFORMACI√ìN
# Convierten el JSON estructurado en texto enriquecido para vectorizar
# ===========================================================================

def json_a_texto_enriquecido(semana: dict) -> str:
    partes = []
    partes.append(f"Semana: {semana['semana_id']} | Inicio: {semana['fecha_inicio']}")

    for dia in semana["dias"]:
        partes.append(f"\n{dia['dia'].upper()} - {dia.get('tipo_bloque_principal') or 'N/A'}")

        # --- CORE ---
        core = dia.get("core")
        if core and core.get("ejercicios"):
            ejercicios_core = ", ".join(
                f"{e['nombre']} {e.get('reps', '')}".strip()
                for e in core["ejercicios"]
            )
            partes.append(f"Core ({core.get('rondas', '?')} rondas): {ejercicios_core}")

        # --- BLOQUE PRINCIPAL ---
        bp = dia.get("bloque_principal")
        if bp:
            sets_reps = f"{bp['sets']}x{bp['reps']}" if bp.get("sets") and bp.get("reps") else ""
            partes.append(f"{bp.get('tipo', 'N/A')}: {bp.get('movimiento', 'N/A')} {sets_reps}".strip())
            if bp.get("variante_principiante"):
                partes.append(f"Principiante: {bp['variante_principiante']}")

        # --- WOD ---
        wod = dia.get("wod")
        if wod:
            duracion_str = ""
            if wod.get("duracion"):
                duracion_str = f"{wod['duracion']}'"
            elif wod.get("rondas"):
                duracion_str = f"{wod['rondas']} rounds"
            elif wod.get("time_cap"):
                duracion_str = f"TC {wod['time_cap']}'"

            partes.append(f"WOD {wod['formato']} {duracion_str}:".strip())
            for ej in wod.get("ejercicios", []):
                linea = f"  - {ej['nombre']} {ej.get('reps', '')}".strip()
                if ej.get("escala"):
                    linea += f" (escala: {ej['escala']})"
                partes.append(linea)

        # --- ACCESORIOS ---
        acc = dia.get("accesorios")
        if acc and acc.get("ejercicios"):
            ejercicios_acc = ", ".join(
                f"{e['nombre']} {e.get('reps', '')}".strip()
                for e in acc["ejercicios"]
            )
            partes.append(f"Accesorios ({acc.get('rondas', '?')} rondas): {ejercicios_acc}")

        # --- METADATA ---
        meta = dia.get("metadata")
        if meta:
            partes.append(f"M√∫sculos: {', '.join(meta.get('grupos_musculares', []))}")
            if meta.get("movimientos_olimpicos"):
                partes.append(f"Ol√≠mpicos: {', '.join(meta['movimientos_olimpicos'])}")
            partes.append(f"Intensidad: {meta.get('intensidad_estimada', 'N/A')}")
            if meta.get("patron_movimiento_fuerza"):
                partes.append(f"Patr√≥n: {meta['patron_movimiento_fuerza']}")

    return "\n".join(partes)



def extraer_metadata_para_chroma(semana: dict) -> dict:
    """
    Extrae los campos de metadata de la semana para almacenarlos como
    filtros en ChromaDB, independientemente del embedding.

    ChromaDB permite guardar metadata junto a cada documento. Esta metadata
    se puede usar para filtrar resultados ANTES de hacer la b√∫squeda vectorial,
    lo que mejora mucho la precisi√≥n del retrieval. Por ejemplo: "dame solo
    semanas que tengan snatch" sin tener que leer todos los embeddings.

    Solo se pueden guardar tipos simples: str, int, float, bool.
    Las listas se convierten a string separado por comas.

    Args:
        semana: Diccionario con la semana completa.

    Returns:
        Diccionario plano con metadata filtrable, compatible con ChromaDB.

    Example:
        >>> meta = extraer_metadata_para_chroma(semana_dict)
        >>> print(meta)
        {
            'semana_id': 'semana_2025_W06',
            'fecha_inicio': '2025-02-03',
            'movimientos_olimpicos': 'clean, snatch',
            'patrones_fuerza': 'sentadilla, empuje, bisagra',
            'total_dias': 5
        }
    """
    # Recopila los movimientos ol√≠mpicos de todos los d√≠as de la semana
    # usando un set para eliminar duplicados (ej: clean puede aparecer lunes y martes)
    todos_olimpicos = set()
    todos_patrones = set()
    todos_grupos = set()

    for dia in semana["dias"]:
        meta = dia["metadata"]
        # Extiende los sets con los valores de cada d√≠a
        todos_olimpicos.update(meta.get("movimientos_olimpicos", []))
        todos_grupos.update(meta.get("grupos_musculares", []))
        if meta.get("patron_movimiento_fuerza"):
            todos_patrones.add(meta["patron_movimiento_fuerza"])

    # Devuelve un diccionario plano con tipos primitivos (requisito de ChromaDB)
    return {
        "semana_id": semana["semana_id"],
        "fecha_inicio": semana["fecha_inicio"],
        # Las listas se convierten a string porque ChromaDB no acepta listas como metadata
        "movimientos_olimpicos": ", ".join(sorted(todos_olimpicos)),
        "patrones_fuerza": ", ".join(sorted(todos_patrones)),
        "grupos_musculares": ", ".join(sorted(todos_grupos)),
        "total_dias": len(semana["dias"]),
    }


# ===========================================================================
# FUNCIONES DE CONEXI√ìN Y CARGA EN CHROMADB
# ===========================================================================

def inicializar_chroma() -> chromadb.Collection:
    """
    Inicializa el cliente de ChromaDB y obtiene (o crea) la colecci√≥n de rutinas.

    ChromaDB puede correr de dos modos:
    - PersistentClient: guarda los datos en disco, los datos sobreviven entre ejecuciones
    - EphemeralClient: solo en memoria, se pierde al cerrar el programa (√∫til para tests)

    Usamos PersistentClient para que las rutinas cargadas persistan entre sesiones.
    El modelo de embeddings por defecto de ChromaDB (all-MiniLM-L6-v2) corre localmente
    sin necesidad de API keys externas, lo que simplifica el setup inicial.

    Returns:
        Colecci√≥n de ChromaDB lista para insertar o consultar documentos.
    """
    # Crea el cliente persistente que guarda los datos en la carpeta CHROMA_DB_PATH
    # Si la carpeta no existe, ChromaDB la crea autom√°ticamente
    cliente = chromadb.PersistentClient(path=CHROMA_DB_PATH)

    # Usa el modelo de embeddings por defecto de ChromaDB
    # all-MiniLM-L6-v2 corre 100% local, es liviano y funciona bien para texto en espa√±ol
    embedding_fn = embedding_functions.DefaultEmbeddingFunction()

    # get_or_create_collection obtiene la colecci√≥n si ya existe, o la crea si no
    # Esto hace que el script sea idempotente: se puede ejecutar varias veces sin error
    coleccion = cliente.get_or_create_collection(
        name=COLLECTION_NAME,
        embedding_function=embedding_fn,
        # cosine es la m√©trica de similitud m√°s apropiada para texto
        # mide el √°ngulo entre vectores, no su magnitud
        metadata={"hnsw:space": "cosine"}
    )

    print(f"‚úÖ ChromaDB inicializado en: {CHROMA_DB_PATH}")
    print(f"üìö Colecci√≥n '{COLLECTION_NAME}': {coleccion.count()} documentos existentes")

    return coleccion


def cargar_semana(coleccion: chromadb.Collection, ruta_json: str) -> bool:
    """
    Carga una semana de rutina desde un archivo JSON a la colecci√≥n de ChromaDB.

    Si la semana ya existe en la colecci√≥n (mismo semana_id), la actualiza
    en lugar de duplicarla. Esto hace que el script sea seguro de ejecutar
    m√∫ltiples veces con los mismos archivos.

    Args:
        coleccion: Colecci√≥n de ChromaDB donde se insertar√° la rutina.
        ruta_json: Ruta al archivo .json procesado por parse_routine.py

    Returns:
        True si la semana fue cargada exitosamente, False si hubo un error.
    """
    # Lee el archivo JSON de la rutina procesada
    ruta = Path(ruta_json)
    if not ruta.exists():
        print(f"‚ö†Ô∏è  Archivo no encontrado: {ruta_json}")
        return False

    # Carga el JSON como diccionario Python
    with open(ruta, "r", encoding="utf-8") as f:
        semana = json.load(f)

    # Usa el semana_id como ID √∫nico del documento en ChromaDB
    # ChromaDB usa este ID para detectar duplicados y hacer upserts
    doc_id = semana["semana_id"]

    # Convierte el JSON a texto enriquecido para vectorizar
    texto = json_a_texto_enriquecido(semana)

    # Extrae la metadata filtrable para guardar junto al embedding
    metadata = extraer_metadata_para_chroma(semana)

    # upsert inserta el documento si no existe, o lo actualiza si ya existe
    # Esto evita duplicados si se ejecuta el script varias veces
    coleccion.upsert(
        ids=[doc_id],               # ID √∫nico del documento
        documents=[texto],           # Texto que se vectorizar√° con el modelo de embeddings
        metadatas=[metadata]         # Metadata filtrable (no se vectoriza)
    )

    print(f"‚úÖ Cargada: {doc_id} ({len(semana['dias'])} d√≠as, {len(texto)} chars)")
    return True


def cargar_todas_las_semanas(coleccion: chromadb.Collection) -> int:
    """
    Carga todos los archivos JSON de la carpeta data/processed/ en ChromaDB.

    Itera sobre todos los archivos .json en la carpeta de datos procesados
    y los carga uno por uno. Los errores individuales no detienen el proceso.

    Args:
        coleccion: Colecci√≥n de ChromaDB donde se insertar√°n las rutinas.

    Returns:
        Cantidad de semanas cargadas exitosamente.
    """
    # Busca todos los archivos .json en la carpeta de datos procesados
    ruta_processed = Path(PROCESSED_DATA_PATH)

    # Verifica que la carpeta exista antes de buscar archivos
    if not ruta_processed.exists():
        print(f"‚ùå La carpeta {PROCESSED_DATA_PATH} no existe. Ejecut√° parse_routine.py primero.")
        return 0

    # glob("*.json") devuelve todos los archivos .json de la carpeta
    archivos_json = list(ruta_processed.glob("*.json"))

    if not archivos_json:
        print(f"‚ö†Ô∏è  No se encontraron archivos JSON en {PROCESSED_DATA_PATH}")
        return 0

    print(f"\nüìÇ Encontrados {len(archivos_json)} archivos JSON para cargar")

    # Contador de semanas cargadas exitosamente
    exitosos = 0

    # Itera sobre cada archivo y lo carga en ChromaDB
    for archivo in sorted(archivos_json):
        # sorted() garantiza que se procesen en orden alfab√©tico (semana_01, semana_02, etc.)
        if cargar_semana(coleccion, str(archivo)):
            exitosos += 1

    return exitosos


def verificar_carga(coleccion: chromadb.Collection) -> None:
    """
    Hace una b√∫squeda de prueba en ChromaDB para verificar que la carga funcion√≥.

    Realiza una consulta simple para confirmar que los embeddings fueron generados
    correctamente y que el retrieval b√°sico funciona antes de pasar al siguiente paso.

    Args:
        coleccion: Colecci√≥n de ChromaDB a verificar.

    Returns:
        None. Imprime el resultado de la b√∫squeda de prueba en consola.
    """
    print("\nüîç Verificando carga con b√∫squeda de prueba...")

    # Consulta de ejemplo: busca rutinas con trabajo de piernas y sentadilla
    # Si la carga funcion√≥ bien, deber√≠a devolver la semana del ejemplo que tiene Front Squat
    resultados = coleccion.query(
        query_texts=["rutina con sentadilla y trabajo de piernas"],
        n_results=min(2, coleccion.count()),  # Pide 2 resultados o menos si hay menos documentos
        include=["documents", "metadatas", "distances"]
    )

    # Itera sobre los resultados para mostrarlos en consola
    for i, (doc, meta, dist) in enumerate(zip(
        resultados["documents"][0],
        resultados["metadatas"][0],
        resultados["distances"][0]
    )):
        # La distancia coseno va de 0 (id√©ntico) a 2 (opuesto)
        # La convertimos a similitud para que sea m√°s intuitiva (1 = id√©ntico, 0 = sin relaci√≥n)
        similitud = round(1 - dist, 3)
        print(f"\n  Resultado {i+1}: {meta['semana_id']} (similitud: {similitud})")
        # Muestra solo las primeras 3 l√≠neas del documento para no saturar la consola
        primeras_lineas = "\n".join(doc.split("\n")[:3])
        print(f"  Preview: {primeras_lineas}...")


# ===========================================================================
# PUNTO DE ENTRADA
# Permite ejecutar el script directamente desde la terminal:
#   python scripts/ingest.py
# ===========================================================================

if __name__ == "__main__":
    """
    Pipeline completo de ingesta:
        1. Inicializa ChromaDB
        2. Carga todas las semanas procesadas
        3. Verifica que el retrieval funciona
    """

    print("üöÄ Iniciando ingesta de rutinas en ChromaDB...\n")

    # Paso 1: Inicializa ChromaDB y obtiene la colecci√≥n
    coleccion = inicializar_chroma()

    # Paso 2: Carga todos los JSONs procesados en la colecci√≥n
    total_cargadas = cargar_todas_las_semanas(coleccion)

    # Muestra resumen de la ingesta
    print(f"\n{'='*50}")
    print(f"üìä Ingesta completada: {total_cargadas} semanas cargadas")
    print(f"üìö Total en ChromaDB: {coleccion.count()} documentos")
    print(f"{'='*50}")

    # Paso 3: Verifica que el retrieval funciona con una b√∫squeda de prueba
    if coleccion.count() > 0:
        verificar_carga(coleccion)
    else:
        print("‚ö†Ô∏è  No hay documentos en la colecci√≥n, saltando verificaci√≥n")

    print("\n‚úÖ Listo para usar en el pipeline RAG")